{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b302bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecmwf.opendata import Client\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../\")))  # set vscode notebook path for module imports\n",
    "\n",
    "from utils.tools import regions_from_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7100560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [i for i in range(0, 144, 3)] + [j for j in range(144, 361, 6)] #get all steps\n",
    "time = 0 if datetime.now().hour < 18 else 12 #get 00z forecast if we are before 12z, else get 12z forecast\n",
    "current_date = datetime.now().date() #select current date forecast\n",
    "var = '2t' #forecast returned variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download forecast data\n",
    "client = Client()\n",
    "result = client.retrieve(\n",
    "    date=current_date, #can be 0 for today, -1 yestarday... if \n",
    "    time=time,\n",
    "    type=\"fc\",  #forecast for HRES\n",
    "    stream='oper',\n",
    "    step=steps,\n",
    "    param=var,\n",
    "    target=\"current.grib2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a6b73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring index file 'current.grib2.5b7b6.idx' older than GRIB file\n"
     ]
    }
   ],
   "source": [
    "#Open the forecast dataset and format the datas\n",
    "ds = xr.open_dataset('current.grib2')\n",
    "forecast_date = ds.time.values #keep track of the forecast run date time\n",
    "us = ds.sel(**{\"latitude\": slice(50, 24), \"longitude\": slice(-125, -67)}) #Slice to get only US \n",
    "us = (us - 273.15) * 1.8 + 32 #Convert kelvin to °F\n",
    "us.attrs['units'] = '°F'\n",
    "\n",
    "us = us.swap_dims({\"step\": \"valid_time\"})\n",
    "\n",
    "#We slice the dataset with valid_times to avoid non complete day between 00z run (complete days) and 12z run (non complete days)\n",
    "us = us.sel(valid_time=slice(pd.Timestamp(pd.Timestamp(ds.time.values).date()) + pd.Timedelta(days=1), #set the dataset at the start of the next day for our first window\n",
    "                             pd.Timestamp(pd.Timestamp(ds.time.values).date()) + pd.Timedelta(days=14, hours=23))) #and just before the last valid_time\n",
    "\n",
    "#Now that we start the first day at 00z for 00z run AND 12z run, resample hourly to daily\n",
    "us_daily = us.resample(valid_time=\"1D\").mean()\n",
    "\n",
    "us_daily_hdd = (65 - us_daily).clip(min=0) #compute HDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8370788",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = xr.open_dataarray('../utils/files/population_regridded_025deg.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20f2e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdd_weighted = us_daily_hdd * pop #Weight the hdd by population for each point in the grid and each valid_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cb54f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [(0,2, 'Day 1-3'), (3,6, 'Day 4-7'), (7,13, 'Day 8-14')]\n",
    "hdd_list = []\n",
    "for horizon in horizons:\n",
    "    #Create horizon date for slicing\n",
    "    first_date = hdd_weighted.valid_time.min().values\n",
    "    start_date = first_date + pd.Timedelta(days=horizon[0])\n",
    "    last_date = first_date + pd.Timedelta(days=horizon[1])\n",
    "\n",
    "    hdd_weighted_horizon = hdd_weighted.sel(valid_time=slice(start_date, last_date)).sum(dim='valid_time') #sumed HDD for every grid point in the horizon\n",
    "\n",
    "    #Make US mean\n",
    "    us_horizon_mean = hdd_weighted_horizon.mean(dim=['latitude', 'longitude']) #Mean every point in the US to have one mean weighted HDD for the horizon\n",
    "    hdd_list.append({'forecast_run_time': forecast_date, 'region': 'US Mean', 'horizon_start': start_date, 'horizon_end': last_date,\n",
    "                    'horizon_label': horizon[2], 'forecast_HDD': us_horizon_mean.t2m.values})\n",
    "    \n",
    "    #Make region means\n",
    "    zone_means = regions_from_xarray(hdd_weighted_horizon)\n",
    "\n",
    "    #For each zone in the horizon, make a new row of data\n",
    "    for zone_name, zone_data in zone_means.items():\n",
    "        hdd_list.append({'forecast_run_time': forecast_date, 'region': zone_name, 'horizon_start': start_date, 'horizon_end': last_date,\n",
    "                         'horizon_label': horizon[2], 'forecast_HDD': zone_data.t2m.values})\n",
    "        \n",
    "#Make a dataframe of values\n",
    "hdd_horizon_df = pd.DataFrame(hdd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b3394d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_run_time</th>\n",
       "      <th>region</th>\n",
       "      <th>horizon_start</th>\n",
       "      <th>horizon_end</th>\n",
       "      <th>horizon_label</th>\n",
       "      <th>forecast_HDD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-29 12:00:00</td>\n",
       "      <td>US Mean</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>Day 1-3</td>\n",
       "      <td>1880703.6095141533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-29 12:00:00</td>\n",
       "      <td>Great Lakes</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>Day 1-3</td>\n",
       "      <td>5509052.74786199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-29 12:00:00</td>\n",
       "      <td>Columbia-Pacific Northwest</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>Day 1-3</td>\n",
       "      <td>705817.3134749037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-29 12:00:00</td>\n",
       "      <td>Missouri Basin</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>Day 1-3</td>\n",
       "      <td>535205.6023810036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-29 12:00:00</td>\n",
       "      <td>North Atlantic-Appalachian</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>Day 1-3</td>\n",
       "      <td>10363919.605481459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    forecast_run_time                      region horizon_start horizon_end  \\\n",
       "0 2026-01-29 12:00:00                     US Mean    2026-01-30  2026-02-01   \n",
       "1 2026-01-29 12:00:00                 Great Lakes    2026-01-30  2026-02-01   \n",
       "2 2026-01-29 12:00:00  Columbia-Pacific Northwest    2026-01-30  2026-02-01   \n",
       "3 2026-01-29 12:00:00              Missouri Basin    2026-01-30  2026-02-01   \n",
       "4 2026-01-29 12:00:00  North Atlantic-Appalachian    2026-01-30  2026-02-01   \n",
       "\n",
       "  horizon_label        forecast_HDD  \n",
       "0       Day 1-3  1880703.6095141533  \n",
       "1       Day 1-3    5509052.74786199  \n",
       "2       Day 1-3   705817.3134749037  \n",
       "3       Day 1-3   535205.6023810036  \n",
       "4       Day 1-3  10363919.605481459  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdd_horizon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379d2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee47b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d99ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
