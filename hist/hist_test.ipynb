{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3b485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a062bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regions_from_xarray(hdd_dataset, pop_dataset):\n",
    "    #Load subregion shapefile\n",
    "    gdf = gpd.read_file('../utils/files/USRegion/12Regions/DOI_12_Unified_Regions_20180801.shp')\n",
    "    gdf = gdf.to_crs(epsg=4326) #reproject file into classical lat lon coordinates\n",
    "    gdf = gdf[['REG_NAME', 'geometry']]\n",
    "    gdf = gdf[~gdf['REG_NAME'].isin(['Alaska', 'Pacific Islands'])] #Remove both of these regions, irrelevant\n",
    "\n",
    "    #Make a point grid from dataset\n",
    "    lon_grid, lat_grid = np.meshgrid(hdd_dataset.longitude.values, hdd_dataset.latitude.values)\n",
    "    coords_flat = list(zip(lon_grid.ravel(), lat_grid.ravel()))\n",
    "\n",
    "    #Make a gdf of dataset grid to prepare for spatial join\n",
    "    gdf_points = gpd.GeoDataFrame({\n",
    "        'latitude': lat_grid.flatten(),\n",
    "        'longitude': lon_grid.flatten(),\n",
    "        'geometry': gpd.points_from_xy([c[0] for c in coords_flat], [c[1] for c in coords_flat])\n",
    "    }, crs=gdf.crs) #Make sure we have the same crs\n",
    "\n",
    "    #Spatial join between the full US grid and the subregions\n",
    "    gdf_joined = gpd.sjoin(gdf_points, gdf[['REG_NAME', 'geometry']], how='inner', predicate='within')\n",
    "\n",
    "    #Find subregions points and mean then to have the mean of a region for a day of year\n",
    "    zone_means = {}\n",
    "    for zone in gdf_joined['REG_NAME'].unique():\n",
    "        zone_pts = gdf_joined[gdf_joined['REG_NAME'] == zone]\n",
    "        zone_data = hdd_dataset.sel(latitude=xr.DataArray(zone_pts['latitude'].values, dims='points'), #Select region points from the xarray dataset\n",
    "                                    longitude=xr.DataArray(zone_pts['longitude'].values, dims='points'),\n",
    "                                    method='nearest')\n",
    "        zone_pop = pop_dataset.sel(latitude=xr.DataArray(zone_pts['latitude'].values, dims='points'), #Select region points from the xarray dataset\n",
    "                                   longitude=xr.DataArray(zone_pts['longitude'].values, dims='points'),\n",
    "                                   method='nearest')\n",
    "        zone_hdd_sum = zone_data.sum(dim='points') #sum the founded points HDD\n",
    "        zone_pop_sum = zone_pop.sum(dim='points') #sum the pop\n",
    "\n",
    "        zone_hdd_sum_pop_weighted = zone_hdd_sum / zone_pop_sum\n",
    "        \n",
    "        zone_means[zone] = zone_hdd_sum_pop_weighted\n",
    "\n",
    "    return zone_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485fe453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Zarr dataset from earthdatahub destine EU\n",
    "ds = xr.open_dataset(\n",
    "    \"https://data.earthdatahub.destine.eu/era5/era5-land-daily-utc-v1.zarr\",\n",
    "    storage_options={\"client_kwargs\":{\"trust_env\":True}},\n",
    "    chunks={},\n",
    "    engine=\"zarr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8e73456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reassign longitude to be -180, 180\n",
    "if ds.longitude.max() > 180:\n",
    "    ds = ds.assign_coords(longitude=((ds.longitude + 180) % 360) - 180)\n",
    "    ds = ds.sortby(\"longitude\")\n",
    "ds_us = ds.sel(**{\"latitude\": slice(50, 24), \"longitude\": slice(-125, -67)}) #Slice to get only US \n",
    "\n",
    "#Format dataset for HDD\n",
    "t2m_us = ds_us.t2m #Keep only 2m temperature\n",
    "t2m_us = (t2m_us - 273.15) * 1.8 + 32 #Convert kelvin to °F\n",
    "t2m_us.attrs['units'] = '°F'\n",
    "t2m_30years_us = t2m_us.sel(valid_time=slice('1990', '2025')) #Select last 30 years\n",
    "\n",
    "hdd = (65 - t2m_30years_us).clip(min=0) #make max(0, 65 - t2m)\n",
    "\n",
    "#Population reggrided to ERA5-Land dataset\n",
    "pop = xr.open_dataarray('../utils/files/population_regridded_01deg.nc') #from reproject_and_align_pop function in tools\n",
    "us_pop_sum = pop.sum(dim=['latitude', 'longitude'])\n",
    "\n",
    "hdd_weighted = hdd * pop #Weight the hdd by population for each point in the grid and each valid_time\n",
    "\n",
    "#Make US sum and format a df\n",
    "us_hdd_sum = hdd_weighted.sum(dim=['latitude', 'longitude']) #Sum every point in the US to have one sum weighted HDD for each valid time\n",
    "us_hdd_sum_per_pop = us_hdd_sum / us_pop_sum\n",
    "us_hdd_sum_per_pop_df = us_hdd_sum_per_pop.to_dataframe(name='US Sum')\n",
    "us_hdd_sum_per_pop_df = us_hdd_sum_per_pop_df[['US Sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2531bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make regions sum and format a df\n",
    "region_list_hdd = []\n",
    "zone_means = regions_from_xarray(hdd_weighted, pop)\n",
    "for zone_name, zone_data in zone_means.items():\n",
    "    us_hdd_sum_per_pop_region_df = zone_data.to_dataframe(name=zone_name)\n",
    "    us_hdd_sum_per_pop_region_df = us_hdd_sum_per_pop_region_df[[zone_name]]\n",
    "    region_list_hdd.append(us_hdd_sum_per_pop_region_df)\n",
    "region_hdd = pd.concat(region_list_hdd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cac79a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hdds = pd.concat([us_hdd_sum_per_pop_df, region_hdd], axis=1)\n",
    "full_hdds = full_hdds.reset_index()\n",
    "full_hdds = full_hdds.rename(columns={'valid_time': 'time'})\n",
    "full_hdds_row = full_hdds.melt(id_vars=['time'], var_name='region', value_name='hdd')\n",
    "full_hdds_row['source'] = 'era5_land'\n",
    "full_hdds_row['data_type'] = 'observation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f07c17dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>region</th>\n",
       "      <th>hdd</th>\n",
       "      <th>source</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>24.909163</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>27.400915</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>23.516171</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-01-04</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>21.049710</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-01-05</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>23.059405</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144634</th>\n",
       "      <td>2025-12-27</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>2.035970</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144635</th>\n",
       "      <td>2025-12-28</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>4.079060</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144636</th>\n",
       "      <td>2025-12-29</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>6.975467</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144637</th>\n",
       "      <td>2025-12-30</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>21.338607</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144638</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>23.365098</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144639 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time               region        hdd     source    data_type\n",
       "0      1990-01-01               US Sum  24.909163  era5_land  observation\n",
       "1      1990-01-02               US Sum  27.400915  era5_land  observation\n",
       "2      1990-01-03               US Sum  23.516171  era5_land  observation\n",
       "3      1990-01-04               US Sum  21.049710  era5_land  observation\n",
       "4      1990-01-05               US Sum  23.059405  era5_land  observation\n",
       "...           ...                  ...        ...        ...          ...\n",
       "144634 2025-12-27  South Atlantic Gulf   2.035970  era5_land  observation\n",
       "144635 2025-12-28  South Atlantic Gulf   4.079060  era5_land  observation\n",
       "144636 2025-12-29  South Atlantic Gulf   6.975467  era5_land  observation\n",
       "144637 2025-12-30  South Atlantic Gulf  21.338607  era5_land  observation\n",
       "144638 2025-12-31  South Atlantic Gulf  23.365098  era5_land  observation\n",
       "\n",
       "[144639 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_hdds_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56b1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../\")))  # set vscode notebook path for module imports\n",
    "\n",
    "from db.repo import ResultsRepository\n",
    "from db.mongo import MongoWrapper\n",
    "from pipeline.config import settings\n",
    "from pipeline.downloader import ERA5LandDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5cdfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5 = {\n",
    "    \"variable\": [\"2m_temperature\"],\n",
    "    \"time\": [\n",
    "        \"00:00\", \"01:00\", \"02:00\",\n",
    "        \"03:00\", \"04:00\", \"05:00\",\n",
    "        \"06:00\", \"07:00\", \"08:00\",\n",
    "        \"09:00\", \"10:00\", \"11:00\",\n",
    "        \"12:00\", \"13:00\", \"14:00\",\n",
    "        \"15:00\", \"16:00\", \"17:00\",\n",
    "        \"18:00\", \"19:00\", \"20:00\",\n",
    "        \"21:00\", \"22:00\", \"23:00\"\n",
    "    ],\n",
    "    \"data_format\": \"grib\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "    \"area\": [50, -125, 24, -67]\n",
    "}\n",
    "d = ERA5LandDownloader(request_era5, '../data/hist_observation.grib')\n",
    "mongo = MongoWrapper(settings.MONGO_URI_PROD, settings.MONGO_DB) #mongo client\n",
    "repo = ResultsRepository(mongo_client=mongo, repo=settings.MONGO_COLLECTION) #mongo repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6569d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ERA5LandDownloader(request_era5, '../data/hist_observation.grib')\n",
    "\n",
    "dates = pd.date_range('2026-01-01', pd.Timestamp(d.check_latest_available()).tz_localize(None))\n",
    "hist_obs_list = []\n",
    "for date in dates:\n",
    "    if d.is_valid_run(pd.Timestamp(date)) and not repo.exists_for_date(pd.Timestamp(date), d.name):\n",
    "        filepath, dt = d.download(pd.Timestamp(date))\n",
    "        df = d.compute(filepath, pd.Timestamp(date))\n",
    "        hist_obs_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a97e856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.concat(hist_obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa4550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
