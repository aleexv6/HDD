{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3b485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a062bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regions_from_xarray(hdd_dataset, pop_dataset):\n",
    "    #Load subregion shapefile\n",
    "    gdf = gpd.read_file('../utils/files/USRegion/12Regions/DOI_12_Unified_Regions_20180801.shp')\n",
    "    gdf = gdf.to_crs(epsg=4326) #reproject file into classical lat lon coordinates\n",
    "    gdf = gdf[['REG_NAME', 'geometry']]\n",
    "    gdf = gdf[~gdf['REG_NAME'].isin(['Alaska', 'Pacific Islands'])] #Remove both of these regions, irrelevant\n",
    "\n",
    "    #Make a point grid from dataset\n",
    "    lon_grid, lat_grid = np.meshgrid(hdd_dataset.longitude.values, hdd_dataset.latitude.values)\n",
    "    coords_flat = list(zip(lon_grid.ravel(), lat_grid.ravel()))\n",
    "\n",
    "    #Make a gdf of dataset grid to prepare for spatial join\n",
    "    gdf_points = gpd.GeoDataFrame({\n",
    "        'latitude': lat_grid.flatten(),\n",
    "        'longitude': lon_grid.flatten(),\n",
    "        'geometry': gpd.points_from_xy([c[0] for c in coords_flat], [c[1] for c in coords_flat])\n",
    "    }, crs=gdf.crs) #Make sure we have the same crs\n",
    "\n",
    "    #Spatial join between the full US grid and the subregions\n",
    "    gdf_joined = gpd.sjoin(gdf_points, gdf[['REG_NAME', 'geometry']], how='inner', predicate='within')\n",
    "\n",
    "    #Find subregions points and mean then to have the mean of a region for a day of year\n",
    "    zone_means = {}\n",
    "    for zone in gdf_joined['REG_NAME'].unique():\n",
    "        zone_pts = gdf_joined[gdf_joined['REG_NAME'] == zone]\n",
    "        zone_data = hdd_dataset.sel(latitude=xr.DataArray(zone_pts['latitude'].values, dims='points'), #Select region points from the xarray dataset\n",
    "                                    longitude=xr.DataArray(zone_pts['longitude'].values, dims='points'),\n",
    "                                    method='nearest')\n",
    "        zone_pop = pop_dataset.sel(latitude=xr.DataArray(zone_pts['latitude'].values, dims='points'), #Select region points from the xarray dataset\n",
    "                                   longitude=xr.DataArray(zone_pts['longitude'].values, dims='points'),\n",
    "                                   method='nearest')\n",
    "        zone_hdd_sum = zone_data.sum(dim='points') #sum the founded points HDD\n",
    "        zone_pop_sum = zone_pop.sum(dim='points') #sum the pop\n",
    "\n",
    "        zone_hdd_sum_pop_weighted = zone_hdd_sum / zone_pop_sum\n",
    "        \n",
    "        zone_means[zone] = zone_hdd_sum_pop_weighted\n",
    "\n",
    "    return zone_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485fe453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexl\\miniconda3\\envs\\geo\\Lib\\site-packages\\zarr\\codecs\\numcodecs\\_codecs.py:163: ZarrUserWarning: Numcodecs codecs are not in the Zarr version 3 specification and may not be supported by other zarr implementations.\n",
      "  super().__init__(**codec_config)\n"
     ]
    }
   ],
   "source": [
    "#Read Zarr dataset from earthdatahub destine EU\n",
    "ds = xr.open_dataset(\n",
    "    \"https://data.earthdatahub.destine.eu/era5/era5-land-daily-utc-v1.zarr\",\n",
    "    storage_options={\"client_kwargs\":{\"trust_env\":True}},\n",
    "    chunks={},\n",
    "    engine=\"zarr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e73456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reassign longitude to be -180, 180\n",
    "if ds.longitude.max() > 180:\n",
    "    ds = ds.assign_coords(longitude=((ds.longitude + 180) % 360) - 180)\n",
    "    ds = ds.sortby(\"longitude\")\n",
    "ds_us = ds.sel(**{\"latitude\": slice(50, 24), \"longitude\": slice(-125, -67)}) #Slice to get only US \n",
    "\n",
    "#Format dataset for HDD\n",
    "t2m_us = ds_us.t2m #Keep only 2m temperature\n",
    "t2m_us = (t2m_us - 273.15) * 1.8 + 32 #Convert kelvin to °F\n",
    "t2m_us.attrs['units'] = '°F'\n",
    "t2m_30years_us = t2m_us.sel(valid_time=slice('1990', '2025')) #Select last 30 years\n",
    "\n",
    "hdd = (65 - t2m_30years_us).clip(min=0) #make max(0, 65 - t2m)\n",
    "\n",
    "#Population reggrided to ERA5-Land dataset\n",
    "pop = xr.open_dataarray('../utils/files/population_regridded_01deg.nc') #from reproject_and_align_pop function in tools\n",
    "us_pop_sum = pop.sum(dim=['latitude', 'longitude'])\n",
    "\n",
    "hdd_weighted = hdd * pop #Weight the hdd by population for each point in the grid and each valid_time\n",
    "\n",
    "#Make US sum and format a df\n",
    "us_hdd_sum = hdd_weighted.sum(dim=['latitude', 'longitude']) #Sum every point in the US to have one sum weighted HDD for each valid time\n",
    "us_hdd_sum_per_pop = us_hdd_sum / us_pop_sum\n",
    "us_hdd_sum_per_pop_df = us_hdd_sum_per_pop.to_dataframe(name='US Sum')\n",
    "us_hdd_sum_per_pop_df = us_hdd_sum_per_pop_df[['US Sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2531bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make regions sum and format a df\n",
    "region_list_hdd = []\n",
    "zone_means = regions_from_xarray(hdd_weighted, pop)\n",
    "for zone_name, zone_data in zone_means.items():\n",
    "    us_hdd_sum_per_pop_region_df = zone_data.to_dataframe(name=zone_name)\n",
    "    us_hdd_sum_per_pop_region_df = us_hdd_sum_per_pop_region_df[[zone_name]]\n",
    "    region_list_hdd.append(us_hdd_sum_per_pop_region_df)\n",
    "region_hdd = pd.concat(region_list_hdd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac79a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hdds = pd.concat([us_hdd_sum_per_pop_df, region_hdd], axis=1)\n",
    "full_hdds = full_hdds.reset_index()\n",
    "full_hdds = full_hdds.rename(columns={'valid_time': 'time'})\n",
    "full_hdds_row = full_hdds.melt(id_vars=['time'], var_name='region', value_name='hdd')\n",
    "full_hdds_row['source'] = 'era5_land'\n",
    "full_hdds_row['data_type'] = 'observation'\n",
    "full_hdds_row['winter_year'] = full_hdds_row['time'].dt.to_period('Y-MAY').dt.start_time.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07c17dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>region</th>\n",
       "      <th>hdd</th>\n",
       "      <th>source</th>\n",
       "      <th>data_type</th>\n",
       "      <th>winter_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>24.909163</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>27.400915</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>23.516171</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-01-04</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>21.049710</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-01-05</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>23.059405</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144634</th>\n",
       "      <td>2025-12-27</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>2.035970</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144635</th>\n",
       "      <td>2025-12-28</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>4.079060</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144636</th>\n",
       "      <td>2025-12-29</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>6.975467</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144637</th>\n",
       "      <td>2025-12-30</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>21.338607</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144638</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>23.365098</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144639 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time               region        hdd     source    data_type  \\\n",
       "0      1990-01-01               US Sum  24.909163  era5_land  observation   \n",
       "1      1990-01-02               US Sum  27.400915  era5_land  observation   \n",
       "2      1990-01-03               US Sum  23.516171  era5_land  observation   \n",
       "3      1990-01-04               US Sum  21.049710  era5_land  observation   \n",
       "4      1990-01-05               US Sum  23.059405  era5_land  observation   \n",
       "...           ...                  ...        ...        ...          ...   \n",
       "144634 2025-12-27  South Atlantic Gulf   2.035970  era5_land  observation   \n",
       "144635 2025-12-28  South Atlantic Gulf   4.079060  era5_land  observation   \n",
       "144636 2025-12-29  South Atlantic Gulf   6.975467  era5_land  observation   \n",
       "144637 2025-12-30  South Atlantic Gulf  21.338607  era5_land  observation   \n",
       "144638 2025-12-31  South Atlantic Gulf  23.365098  era5_land  observation   \n",
       "\n",
       "        winter_year  \n",
       "0              1989  \n",
       "1              1989  \n",
       "2              1989  \n",
       "3              1989  \n",
       "4              1989  \n",
       "...             ...  \n",
       "144634         2025  \n",
       "144635         2025  \n",
       "144636         2025  \n",
       "144637         2025  \n",
       "144638         2025  \n",
       "\n",
       "[144639 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_hdds_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56b1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../\")))  # set vscode notebook path for module imports\n",
    "\n",
    "from db.repo import ResultsRepository\n",
    "from db.mongo import MongoWrapper\n",
    "from pipeline.config import settings\n",
    "from pipeline.downloader import ERA5LandDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc5cdfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5 = {\n",
    "    \"variable\": [\"2m_temperature\"],\n",
    "    \"time\": [\n",
    "        \"00:00\", \"01:00\", \"02:00\",\n",
    "        \"03:00\", \"04:00\", \"05:00\",\n",
    "        \"06:00\", \"07:00\", \"08:00\",\n",
    "        \"09:00\", \"10:00\", \"11:00\",\n",
    "        \"12:00\", \"13:00\", \"14:00\",\n",
    "        \"15:00\", \"16:00\", \"17:00\",\n",
    "        \"18:00\", \"19:00\", \"20:00\",\n",
    "        \"21:00\", \"22:00\", \"23:00\"\n",
    "    ],\n",
    "    \"data_format\": \"grib\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "    \"area\": [50, -125, 24, -67]\n",
    "}\n",
    "d = ERA5LandDownloader(request_era5, '../data/hist_observation.grib')\n",
    "mongo = MongoWrapper(settings.MONGO_URI_PROD, settings.MONGO_DB) #mongo client\n",
    "repo = ResultsRepository(mongo_client=mongo, repo=settings.MONGO_COLLECTION) #mongo repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6569d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ERA5LandDownloader(request_era5, '../data/hist_observation.grib')\n",
    "\n",
    "dates = pd.date_range('2026-01-01', pd.Timestamp(d.check_latest_available()).tz_localize(None))\n",
    "hist_obs_list = []\n",
    "for date in dates:\n",
    "    if d.is_valid_run(pd.Timestamp(date)) and not repo.exists_for_date(pd.Timestamp(date), d.name):\n",
    "        filepath, dt = d.download(pd.Timestamp(date))\n",
    "        df = d.compute(filepath, pd.Timestamp(date))\n",
    "        hist_obs_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "997bc6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_obs_df = pd.concat(hist_obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97202e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>region</th>\n",
       "      <th>hdd</th>\n",
       "      <th>source</th>\n",
       "      <th>data_type</th>\n",
       "      <th>winter_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-01</td>\n",
       "      <td>US Sum</td>\n",
       "      <td>27.122040</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-01</td>\n",
       "      <td>Great Lakes</td>\n",
       "      <td>47.054868</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-01</td>\n",
       "      <td>Columbia-Pacific Northwest</td>\n",
       "      <td>28.647442</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-01</td>\n",
       "      <td>Missouri Basin</td>\n",
       "      <td>35.279531</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-01</td>\n",
       "      <td>North Atlantic-Appalachian</td>\n",
       "      <td>37.638977</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>California-Great Basin</td>\n",
       "      <td>11.882677</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>Mississippi Basin</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>Lower Colorado Basin</td>\n",
       "      <td>3.546683</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>Arkansas-Rio Grande-Texas Gulf</td>\n",
       "      <td>13.279570</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>South Atlantic Gulf</td>\n",
       "      <td>16.882128</td>\n",
       "      <td>era5_land</td>\n",
       "      <td>observation</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time                          region        hdd     source  \\\n",
       "0  2026-01-01                          US Sum  27.122040  era5_land   \n",
       "1  2026-01-01                     Great Lakes  47.054868  era5_land   \n",
       "2  2026-01-01      Columbia-Pacific Northwest  28.647442  era5_land   \n",
       "3  2026-01-01                  Missouri Basin  35.279531  era5_land   \n",
       "4  2026-01-01      North Atlantic-Appalachian  37.638977  era5_land   \n",
       "..        ...                             ...        ...        ...   \n",
       "6  2026-02-04          California-Great Basin  11.882677  era5_land   \n",
       "7  2026-02-04               Mississippi Basin  27.863333  era5_land   \n",
       "8  2026-02-04            Lower Colorado Basin   3.546683  era5_land   \n",
       "9  2026-02-04  Arkansas-Rio Grande-Texas Gulf  13.279570  era5_land   \n",
       "10 2026-02-04             South Atlantic Gulf  16.882128  era5_land   \n",
       "\n",
       "      data_type  winter_year  \n",
       "0   observation         2025  \n",
       "1   observation         2025  \n",
       "2   observation         2025  \n",
       "3   observation         2025  \n",
       "4   observation         2025  \n",
       "..          ...          ...  \n",
       "6   observation         2025  \n",
       "7   observation         2025  \n",
       "8   observation         2025  \n",
       "9   observation         2025  \n",
       "10  observation         2025  \n",
       "\n",
       "[385 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_obs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbde7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
